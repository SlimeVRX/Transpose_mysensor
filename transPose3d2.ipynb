{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import torch\n",
    "from torch import optim\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "from model import *\n",
    "from dataset_loader import create_data_loader\n",
    "from loss_func import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001 # 学习率\n",
    "epoches = 2000 #训练次数\n",
    "batch_size = 256 # 每一个训练批次数量\n",
    "start_epoch = 0\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "poseS1 = PoseS1().to(device)\n",
    "poseS2 = PoseS2().to(device)\n",
    "poseS3 = PoseS3().to(device)\n",
    "transB1 = TransB1().to(device)\n",
    "transB2 = TransB2().to(device)\n",
    "\n",
    "Ls1 = poseLoss # 叶关节点位置的loss\n",
    "Ls2 = poseLoss # 除胯外的关节位置的loss\n",
    "Ls3 = poseLoss # 除胯外的关节6d旋转的loss\n",
    "Lb1 = crossEntropy # 接触脚的概率\n",
    "Lb2 = ver_n_loss # 连续1,3,9,27帧的位移loss\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad,  itertools.chain(poseS1.parameters(),\n",
    "                                       poseS2.parameters(),\n",
    "                                       poseS3.parameters(),\n",
    "                                       transB1.parameters(),\n",
    "                                       transB2.parameters())), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    global start_epoch\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    models = checkpoint['modes'] # 提取网络结构\n",
    "    models_state_dict = checkpoint['models_state_dict']  # 提取网络结构\n",
    "    for model, state_dict in zip([poseS1,  poseS2, poseS3, transB1, transB2], models_state_dict):\n",
    "        model.load_state_dict(state_dict)  # 加载网络权重参数\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])  # 加载优化器参数\n",
    "    \n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = True\n",
    "    model.train()\n",
    "    \n",
    "    return models\n",
    "models = load_checkpoint(\"./checkpoint/checkpoint_best_transB1.pth\")\n",
    "for p in poseS1.parameters():\n",
    "    p.requires_grad=False\n",
    "for p in poseS2.parameters():\n",
    "    p.requires_grad=False\n",
    "for p in poseS3.parameters():\n",
    "    p.requires_grad=False\n",
    "for p in transB1.parameters():\n",
    "    p.requires_grad=False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小36858， 验证集大小9215， 测试集大小46073\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, valid_loader = create_data_loader(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc718d3a879340f78c0f64283ecebf4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/143 [00:00<?, ?it/s, training]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epoches):\n",
    "    i = 0\n",
    "    loss_sum = 0\n",
    "    loss_dict = {\"loss_ls1\":0, \"loss_ls2\":0, \"loss_ls3\":0, \"loss_lb1\":0, \"loss_lb2\":0, \"foot_acc\":0}\n",
    "    bar = tqdm(enumerate(iter(train_loader)),postfix=\"training\", total =len(train_loader))\n",
    "\n",
    "    for idx, (seq_len, x0, p_leaf_gt, p_all_gt, pose_6d_gt, support_leg_gt, root_velocity_gt, root_ori, mask) in bar:\n",
    "        poseS1.train()\n",
    "        poseS2.train()\n",
    "        poseS3.train()\n",
    "        transB1.train()\n",
    "        transB2.train()\n",
    "\n",
    "        x0 = x0.to(device)\n",
    "        p_leaf_gt = p_leaf_gt.to(device)\n",
    "        p_all_gt = p_all_gt.to(device)\n",
    "        pose_6d_gt = pose_6d_gt.to(device)\n",
    "        support_leg_gt = support_leg_gt.to(device)\n",
    "        root_velocity_gt = root_velocity_gt.to(device)\n",
    "        root_ori = root_ori.to(device)\n",
    "        mask = mask.to(device)\n",
    "        \n",
    "\n",
    "        # --------pose 1\n",
    "        p_leaf = poseS1(x0, seq_len)\n",
    "        loss_ls1 = Ls1(p_leaf, p_leaf_gt.to(device) + torch.normal(mean=0, std=0.04, size=p_leaf_gt.shape).to(device), mask)\n",
    "        loss_dict[\"loss_ls1\"] += loss_ls1.item()\n",
    "        # --------pose 2\n",
    "        x1 = torch.cat([p_leaf, x0], dim=-1)\n",
    "        p_all = poseS2(x1, seq_len)\n",
    "        loss_ls2 = Ls2(p_all, p_all_gt.to(device) + torch.normal(mean=0, std=0.025, size=p_all_gt.shape).to(device), mask)\n",
    "        loss_dict[\"loss_ls2\"] += loss_ls2.item()\n",
    "        # --------pose 3\n",
    "        x2 = torch.cat([p_all, x0], dim=-1)\n",
    "        r6d_all = poseS3(x2, seq_len)\n",
    "        loss_ls3 = Ls3(r6d_all, pose_6d_gt, mask)\n",
    "        loss_dict[\"loss_ls3\"] += loss_ls3.item()\n",
    "        # --------transB1\n",
    "        support_leg_prob = transB1(x1, seq_len)\n",
    "\n",
    "        loss_lb1 = Lb1(support_leg_prob, support_leg_gt, mask)\n",
    "        foot_acc = foot_accuracy(support_leg_prob, support_leg_gt, mask)\n",
    "        loss_dict[\"loss_lb1\"] += loss_lb1.item()\n",
    "        loss_dict[\"foot_acc\"] += foot_acc.item() * 100\n",
    "        # --------transB2\n",
    "        ve_hat = transB2(x2 + torch.normal(mean=0, std=0.025, size=x2.shape).to(device), seq_len)\n",
    "        loss_lb2 = Lb2(ve_hat , root_velocity_gt , mask)\n",
    "        loss_dict[\"loss_lb2\"] += loss_lb2.item()\n",
    "        # --------end\n",
    "        \n",
    "        # cal angle error\n",
    "        #avg_error = compute_angle_dif(r6d_all.detach().cpu(), pose_6d_gt.detach().cpu(), mask.detach().cpu())\n",
    "        avg_error = 0\n",
    "        loss_total = loss_lb2\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_sum += loss_total.item()\n",
    "        loss_total.backward()\n",
    "        optimizer.step()\n",
    "        i+=1\n",
    "        bar.set_description(f\"[Epoch {epoch+1}/ {epoches}]\")\n",
    "        bar.set_postfix(total_loss= loss_sum / i, avg_angle_error=avg_error,**{key: value / i for key, value in loss_dict.items()})\n",
    "\n",
    "        if idx%30 == 0:\n",
    "            checkpoint = {'modes': [PoseS1(), PoseS2(),PoseS3(),TransB1(),TransB2()],  \n",
    "    'models_state_dict': [poseS1.state_dict(),poseS2.state_dict(), poseS3.state_dict(),transB1.state_dict(),transB2.state_dict()],\n",
    "    'optimizer_state_dict': optimizer.state_dict(),'epoch': epoch}\n",
    "            torch.save(checkpoint, f'checkpoint/checkpoint_latest.pth')\n",
    "            \n",
    "            # get sample\n",
    "            sample_idx = 0\n",
    "            v_gt = root_velocity_gt[sample_idx][mask[sample_idx].int().bool()].reshape(-1, 3) / 60\n",
    "            v_pre = ve_hat[sample_idx][mask[sample_idx].int().bool()].reshape(-1, 3)\n",
    "            foot_pre = support_leg_prob[sample_idx][mask[sample_idx].int().bool()].reshape(-1, 2)\n",
    "            foot_gt = support_leg_gt[sample_idx][mask[sample_idx].int().bool()].reshape(-1, 2)\n",
    "\n",
    "        # print(v_gt)\n",
    "            sample_dict = {\"pose\": r6d_all[sample_idx][mask[sample_idx].int().bool()].detach().cpu().numpy(), \n",
    "                                            'pose_gt':pose_6d_gt[sample_idx][mask[sample_idx].int().bool()].detach().cpu().numpy(), \n",
    "                                            'leg': support_leg_prob[sample_idx][mask[sample_idx].int().bool()].detach().cpu().numpy(),\n",
    "                                            'leg_gt': support_leg_gt[sample_idx][mask[sample_idx].int().bool()].detach().cpu().numpy(),\n",
    "                                        'foot_pre': foot_pre.detach().cpu().numpy(),\n",
    "                                        'foot_gt': foot_gt.detach().cpu().numpy(),\n",
    "                                        'v': v_pre.detach().cpu().numpy(),\n",
    "                                            'v_gt': v_gt.detach().cpu().numpy(),\n",
    "                                            'root_ori':root_ori[sample_idx][mask[sample_idx].int().bool()].detach().cpu().numpy()\n",
    "                                            }\n",
    "            pickle.dump(sample_dict, open(f'sample/sample_data_{epoch}_{idx}.pkl', 'wb'))\n",
    "\n",
    "\n",
    "    checkpoint = {'modes': [PoseS1(), PoseS2(),PoseS3(),TransB1(),TransB2()],  \n",
    "    'models_state_dict': [poseS1.state_dict(),poseS2.state_dict(), poseS3.state_dict(),transB1.state_dict(),transB2.state_dict()],\n",
    "    'optimizer_state_dict': optimizer.state_dict(),'epoch': epoch}\n",
    "    torch.save(checkpoint, f'checkpoint/checkpoint_{epoch+1}_pose1.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3810jvsc74a57bd0e1617654b9a844d1d5c3f39905eff0ee5c78cb466aa242fb2d2abfff0dae271b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}